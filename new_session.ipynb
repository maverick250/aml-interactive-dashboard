{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b4d1e3c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ca7a1cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d674f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from typing import Tuple, Dict\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 1. Loader ----------------------------------------------------------------\n",
    "def load_transactions(csv_path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Read the raw AML CSV and parse timestamps.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(csv_path, parse_dates=[\"tx_datetime\"])\n",
    "    # Normalise column names if you expect user-supplied files\n",
    "    return df\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 2. Helper filters --------------------------------------------------------\n",
    "def window(df: pd.DataFrame, start, end) -> pd.DataFrame:\n",
    "    \"\"\"Return rows whose tx_datetime falls inside [start, end].\"\"\"\n",
    "    mask = (df.tx_datetime >= start) & (df.tx_datetime <= end)\n",
    "    return df.loc[mask].copy()\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 3. KPI engines -----------------------------------------------------------\n",
    "def totals(df: pd.DataFrame) -> Dict[str, Dict[str, float]]:\n",
    "    \"\"\"\n",
    "    Return count & ZAR value of deposits and withdrawals.\n",
    "    \"\"\"\n",
    "    dep = df[df.amount > 0]\n",
    "    wd  = df[df.amount < 0]\n",
    "\n",
    "    return {\n",
    "        \"deposits\": {\n",
    "            \"count\": len(dep),\n",
    "            \"value\": dep.amount.sum()\n",
    "        },\n",
    "        \"withdrawals\": {\n",
    "            \"count\": len(wd),\n",
    "            \"value\": wd.amount.abs().sum()   # absolute for readability\n",
    "        }\n",
    "    }\n",
    "\n",
    "\n",
    "def hourly_bursts(df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Transactions per hour (index 0-23).\n",
    "    \"\"\"\n",
    "    return (\n",
    "        df.assign(hour=df.tx_datetime.dt.hour)\n",
    "          .groupby(\"hour\")[\"amount\"]\n",
    "          .size()\n",
    "          .reindex(range(24), fill_value=0)\n",
    "    )\n",
    "\n",
    "\n",
    "def domestic_split(df: pd.DataFrame, home_code: str = \"ZA\") -> Dict[str, Dict[str, float]]:\n",
    "    \"\"\"\n",
    "    Counts and totals for domestic vs international.\n",
    "    \"\"\"\n",
    "    df = df.assign(is_domestic=df.counterparty_country_code.eq(home_code))\n",
    "    grp = df.groupby(\"is_domestic\")[\"amount\"].agg([\"count\", \"sum\"])\n",
    "\n",
    "    def row(flag: bool):\n",
    "        row = grp.loc[flag] if flag in grp.index else {\"count\": 0, \"sum\": 0.0}\n",
    "        return {\"count\": int(row[\"count\"]), \"value\": float(abs(row[\"sum\"]))}\n",
    "\n",
    "    return {\n",
    "        \"domestic\":      row(True),\n",
    "        \"international\": row(False)\n",
    "    }\n",
    "\n",
    "\n",
    "def extremes(df: pd.DataFrame) -> Dict[str, pd.Series]:\n",
    "    \"\"\"\n",
    "    Largest deposit & withdrawal rows (entire records for drill-down).\n",
    "    \"\"\"\n",
    "    largest_dep = df[df.amount > 0].nlargest(1, \"amount\").squeeze()\n",
    "    largest_wd  = df[df.amount < 0].nsmallest(1, \"amount\").squeeze()\n",
    "    return {\"largest_deposit\": largest_dep, \"largest_withdrawal\": largest_wd}\n",
    "\n",
    "\n",
    "def channel_mix(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Count & value by channel, sorted by total value.\n",
    "    \"\"\"\n",
    "    return (\n",
    "        df.groupby(\"channel\")[\"amount\"]\n",
    "          .agg(count=\"size\", value=\"sum\")\n",
    "          .abs()                     # withdrawals should be positive in the KPI\n",
    "          .sort_values(\"value\", ascending=False)\n",
    "    )\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 4. Convenience wrapper --------------------------------------------------\n",
    "def kpi_bundle(df: pd.DataFrame, start, end) -> Dict:\n",
    "    \"\"\"\n",
    "    One-stop shop that returns all required insights for the UI.\n",
    "    \"\"\"\n",
    "    dfw = window(df, start, end)\n",
    "\n",
    "    return {\n",
    "        \"totals\":          totals(dfw),\n",
    "        \"per_hour\":        hourly_bursts(dfw).to_dict(),\n",
    "        \"domestic_split\":  domestic_split(dfw),\n",
    "        \"extremes\":        extremes(dfw),          # full rows for tooltip/table\n",
    "        \"channel_mix\":     channel_mix(dfw).to_dict(orient=\"index\")\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4acfebe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'totals': {'deposits': {'count': 5, 'value': np.float64(103885.31)}, 'withdrawals': {'count': 7, 'value': np.float64(32120.12)}}, 'per_hour': {0: 0, 1: 0, 2: 0, 3: 2, 4: 0, 5: 1, 6: 1, 7: 0, 8: 0, 9: 0, 10: 1, 11: 1, 12: 0, 13: 0, 14: 0, 15: 1, 16: 0, 17: 0, 18: 3, 19: 0, 20: 0, 21: 1, 22: 1, 23: 0}, 'domestic_split': {'domestic': {'count': 6, 'value': 1609.2799999999988}, 'international': {'count': 6, 'value': 70155.90999999999}}, 'extremes': {'largest_deposit': transaction_id                          TX000149\n",
      "account_id                              ACC12345\n",
      "tx_datetime                  2025-06-04 03:06:54\n",
      "amount                                  78697.12\n",
      "channel                                      EFT\n",
      "counterparty_country_code                     DE\n",
      "Name: 148, dtype: object, 'largest_withdrawal': transaction_id                          TX000500\n",
      "account_id                              ACC12345\n",
      "tx_datetime                  2025-06-24 21:15:24\n",
      "amount                                 -10832.61\n",
      "channel                                 SmartApp\n",
      "counterparty_country_code                     ZA\n",
      "Name: 499, dtype: object}, 'channel_mix': {'EFT': {'count': 4, 'value': 74700.59999999999}, 'Cash': {'count': 3, 'value': 7701.27}, 'SmartApp': {'count': 5, 'value': 4765.859999999999}}}\n"
     ]
    }
   ],
   "source": [
    "df = load_transactions(\"aml_synthetic_transactions.csv\")\n",
    "metrics = kpi_bundle(df, \"2025-06-01\", \"2025-06-30\")\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e99efae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------  1. RULE-BASED SPOTLIGHTS  ----------\n",
    "from datetime import timedelta\n",
    "\n",
    "def spotlights(df_window: pd.DataFrame, df_history: pd.DataFrame) -> dict:\n",
    "    \"\"\"\n",
    "    Return boolean flags + quantitative context for UI badges.\n",
    "    \"\"\"\n",
    "    out = {}\n",
    "    \n",
    "    # Burst: compare hourly max of window vs 90-day median of hourly counts\n",
    "    window_hourly = df_window.tx_datetime.dt.hour.value_counts()\n",
    "    hist_90d_start = df_window.tx_datetime.max() - timedelta(days=90)\n",
    "    historic = df_history[df_history.tx_datetime >= hist_90d_start]\n",
    "    hist_hourly_med = historic.tx_datetime.dt.hour.value_counts().median()\n",
    "    burst_score = window_hourly.max() / max(hist_hourly_med, 1)  # avoid divide-by-zero\n",
    "    \n",
    "    out[\"hourly_burst\"] = {\n",
    "        \"flag\": burst_score > 3,\n",
    "        \"score\": burst_score,\n",
    "        \"hour\": window_hourly.idxmax()\n",
    "    }\n",
    "    \n",
    "    # Inflow/outflow imbalance\n",
    "    dep_sum = df_window[df_window.amount > 0].amount.sum()\n",
    "    wd_sum  = abs(df_window[df_window.amount < 0].amount.sum())\n",
    "    ratio   = wd_sum / dep_sum if dep_sum else float('inf')\n",
    "    out[\"imbalance\"] = {\"flag\": ratio > 1.2, \"ratio\": ratio}\n",
    "    \n",
    "    # Extreme deposit percentile\n",
    "    p95 = df_history[df_history.amount > 0].amount.quantile(0.95)\n",
    "    max_dep = df_window[df_window.amount > 0].amount.max()\n",
    "    out[\"extreme_deposit\"] = {\"flag\": max_dep > p95, \"value\": max_dep, \"p95\": p95}\n",
    "    \n",
    "    return out\n",
    "\n",
    "\n",
    "# ----------  2. LLM NARRATIVE (optional)  ----------\n",
    "import openai   # pip install --upgrade openai\n",
    "import json\n",
    "\n",
    "def narrative(metrics: dict, spotlights: dict) -> str:\n",
    "    \"\"\"\n",
    "    Send metrics + spotlight flags to GPT and receive a short compliance note.\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"You are an AML analyst.\n",
    "    The following JSON contains KPI metrics and spotlight flags for a\n",
    "    30-day transaction window. Write a concise, professional summary that:\n",
    "    • Mentions any flagged anomalies.\n",
    "    • Quantifies them (values, percentages, timestamps).\n",
    "    • Uses bullet points; max 120 words.\n",
    "\n",
    "    JSON:\n",
    "    {json.dumps({\"metrics\": metrics, \"spotlights\": spotlights}, indent=2)}\n",
    "    \"\"\"\n",
    "    resp = openai.ChatCompletion.create(\n",
    "          model=\"gpt-4o-mini\",\n",
    "          messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "          max_tokens=200,\n",
    "          temperature=0.2\n",
    "    )\n",
    "    return resp.choices[0].message.content.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b0e224",
   "metadata": {},
   "outputs": [],
   "source": [
    "def totals(df):\n",
    "    by_type = df.groupby(\"is_deposit\")[\"amount\"].agg(['count','sum'])\n",
    "    return by_type.loc[True], by_type.loc[False]\n",
    "\n",
    "def hourly(df):\n",
    "    return df.groupby(\"hour\")[\"amount\"].size()\n",
    "\n",
    "def home_vs_away(df):\n",
    "    g = df.groupby(\"is_domestic\")[\"amount\"].agg(['count','sum'])\n",
    "    return g.loc[True], g.loc[False]\n",
    "\n",
    "def extremes(df):\n",
    "    largest_dep = df[df.amount>0].nlargest(1, \"amount\")\n",
    "    largest_wd  = df[df.amount<0].nsmallest(1, \"amount\")\n",
    "    return largest_dep, largest_wd\n",
    "\n",
    "def channels(df):\n",
    "    return df.groupby(\"channel\")[\"amount\"].agg(['count','sum']).sort_values('sum', ascending=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
